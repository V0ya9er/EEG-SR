#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®éªŒè¿è¡Œæ¨¡å—

æä¾›å®éªŒæ‰§è¡Œé€»è¾‘ï¼ŒåŒ…æ‹¬è®­ç»ƒã€åˆ†æã€å¯è§†åŒ–ç­‰ã€‚
æ”¯æŒæ™ºèƒ½å¤š GPU å¹¶è¡Œæ‰¹é‡ LOSO å®éªŒã€‚
"""

import os
import subprocess
import platform
import datetime
import multiprocessing as mp
from pathlib import Path
from typing import List, Optional, Tuple
from queue import Empty

from .config import ExperimentConfig
from .ui import (
    print_menu_header, print_separator, print_success, print_error,
    print_warning, print_info, wait_for_enter, confirm, ProgressBar
)


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def run_command(cmd: List[str], description: str = "", 
                show_output: bool = True) -> Tuple[bool, str]:
    """
    è¿è¡Œå‘½ä»¤
    
    Args:
        cmd: å‘½ä»¤åˆ—è¡¨
        description: å‘½ä»¤æè¿°
        show_output: æ˜¯å¦æ˜¾ç¤ºè¾“å‡º
        
    Returns:
        (æ˜¯å¦æˆåŠŸ, è¾“å‡ºå†…å®¹)
    """
    if description:
        print(f"\n{description}")
    
    print(f"æ‰§è¡Œ: {' '.join(cmd)}")
    print()
    
    try:
        if show_output:
            result = subprocess.run(cmd)
            return result.returncode == 0, ""
        else:
            result = subprocess.run(cmd, capture_output=True, text=True)
            return result.returncode == 0, result.stdout + result.stderr
    except Exception as e:
        print_error(f"æ‰§è¡Œé”™è¯¯: {e}")
        return False, str(e)


def find_latest_checkpoint() -> Optional[str]:
    """æŸ¥æ‰¾æœ€æ–°çš„æ£€æŸ¥ç‚¹æ–‡ä»¶"""
    logs_dir = Path("lightning_logs")
    if not logs_dir.exists():
        return None
    
    versions = sorted(
        logs_dir.glob("version_*"),
        key=lambda p: p.stat().st_mtime,
        reverse=True
    )
    
    for version in versions:
        ckpt_dir = version / "checkpoints"
        if not ckpt_dir.exists():
            continue
        
        ckpts = list(ckpt_dir.glob("*.ckpt"))
        if ckpts:
            # ä¼˜å…ˆé€‰æ‹© best æ¨¡å‹
            best_ckpts = [c for c in ckpts if "best" in c.name.lower()]
            if best_ckpts:
                return str(best_ckpts[0])
            # è¿”å›æœ€æ–°çš„ä¸€ä¸ªæ£€æŸ¥ç‚¹
            latest_ckpt = sorted(
                ckpts,
                key=lambda p: p.stat().st_mtime,
                reverse=True
            )[0]
            return str(latest_ckpt)
    
    return None


def find_latest_loso_output_dir(exp_name: str = None) -> Optional[str]:
    """
    æŸ¥æ‰¾æœ€æ–°çš„ LOSO å®éªŒè¾“å‡ºç›®å½•
    
    æœç´¢èŒƒå›´ï¼š
    1. ./results/loso/ ç›®å½•ä¸‹çš„å­ç›®å½•
    2. ./results/ ç›®å½•ä¸‹åŒ…å« "loso" çš„å­ç›®å½•ï¼ˆå¦‚ conformer_bci2a_loso_additive_gaussianï¼‰
    
    Args:
        exp_name: å¯é€‰çš„å®éªŒåç§°å‰ç¼€
    
    Returns:
        æœ€æ–°çš„è¾“å‡ºç›®å½•è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å› None
    """
    results_dir = Path("./results")
    if not results_dir.exists():
        return None
    
    all_dirs = []
    
    # æœç´¢ ./results/loso/ ä¸‹çš„ç›®å½•
    loso_dir = results_dir / "loso"
    if loso_dir.exists():
        if exp_name:
            all_dirs.extend(loso_dir.glob(f"{exp_name}*"))
        else:
            all_dirs.extend([d for d in loso_dir.iterdir() if d.is_dir()])
    
    # æœç´¢ ./results/ ä¸‹åŒ…å« "loso" çš„ç›®å½•
    for d in results_dir.iterdir():
        if d.is_dir() and d.name != "loso" and "loso" in d.name.lower():
            if exp_name:
                if d.name.startswith(exp_name) or exp_name in d.name:
                    all_dirs.append(d)
            else:
                all_dirs.append(d)
    
    if not all_dirs:
        return None
    
    # å»é‡å¹¶æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
    unique_dirs = list(set(all_dirs))
    unique_dirs.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return str(unique_dirs[0])


def find_latest_experiment_results() -> Optional[str]:
    """
    æ™ºèƒ½æŸ¥æ‰¾æœ€æ–°çš„å®éªŒç»“æœç›®å½•
    ä¼˜å…ˆçº§: results/ ä¸‹æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ŒæŸ¥æ‰¾åŒ…å« noise_sweep_results.csv çš„ç›®å½•
    
    Returns:
        æœ€æ–°çš„ç»“æœç›®å½•è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å› None
    """
    results_dir = Path("./results")
    if not results_dir.exists():
        return None
    
    # æ”¶é›†æ‰€æœ‰åŒ…å« noise_sweep_results.csv çš„ç›®å½•
    valid_dirs = []
    for csv_file in results_dir.rglob("noise_sweep_results.csv"):
        valid_dirs.append(csv_file.parent)
    
    if not valid_dirs:
        return None
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
    valid_dirs.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return str(valid_dirs[0])


def find_checkpoint_in_dir(directory: str) -> Optional[str]:
    """
    åœ¨æŒ‡å®šç›®å½•ä¸­æŸ¥æ‰¾ checkpoint æ–‡ä»¶
    
    Args:
        directory: ç›®å½•è·¯å¾„
    
    Returns:
        checkpoint è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å› None
    """
    dir_path = Path(directory)
    if not dir_path.exists():
        return None
    
    # æŸ¥æ‰¾ checkpoints å­ç›®å½•
    ckpt_dirs = list(dir_path.rglob("checkpoints"))
    
    for ckpt_dir in ckpt_dirs:
        ckpts = list(ckpt_dir.glob("*.ckpt"))
        if ckpts:
            # ä¼˜å…ˆé€‰æ‹© best æ¨¡å‹
            best_ckpts = [c for c in ckpts if "best" in c.name.lower()]
            if best_ckpts:
                return str(best_ckpts[0])
            # è¿”å›æœ€æ–°çš„ä¸€ä¸ªæ£€æŸ¥ç‚¹
            latest_ckpt = sorted(
                ckpts,
                key=lambda p: p.stat().st_mtime,
                reverse=True
            )[0]
            return str(latest_ckpt)
    
    return None


def find_latest_version_dir() -> Optional[str]:
    """æŸ¥æ‰¾æœ€æ–°çš„ lightning_logs ç‰ˆæœ¬ç›®å½•"""
    logs_dir = Path("lightning_logs")
    if not logs_dir.exists():
        return None
    
    versions = sorted(
        logs_dir.glob("version_*"), 
        key=lambda p: p.stat().st_mtime, 
        reverse=True
    )
    
    if versions:
        return str(versions[0])
    return None


def get_checkpoint_info(version_dir: Path) -> str:
    """ä» hparams.yaml è·å–æ£€æŸ¥ç‚¹ä¿¡æ¯"""
    hparams_path = version_dir / "hparams.yaml"
    info = []
    
    if hparams_path.exists():
        try:
            with open(hparams_path, "r", encoding="utf-8") as f:
                content = f.read()
                for line in content.splitlines():
                    if "model_name:" in line:
                        info.append(f"Model: {line.split(':')[-1].strip()}")
                    elif "dataset_name:" in line:
                        info.append(f"Dataset: {line.split(':')[-1].strip()}")
                    elif "mechanism_name:" in line:
                        info.append(f"SR: {line.split(':')[-1].strip()}")
                    elif "noise_name:" in line:
                        info.append(f"Noise: {line.split(':')[-1].strip()}")
        except Exception:
            pass
    
    return ", ".join(info) if info else "æ— è¯¦ç»†ä¿¡æ¯"


def select_checkpoint() -> Optional[str]:
    """äº¤äº’å¼é€‰æ‹©æ£€æŸ¥ç‚¹"""
    logs_dir = Path("lightning_logs")
    if not logs_dir.exists():
        print_error("æœªæ‰¾åˆ° lightning_logs ç›®å½•")
        return None
    
    versions = sorted(
        logs_dir.glob("version_*"), 
        key=lambda p: p.stat().st_mtime, 
        reverse=True
    )
    
    valid_versions = []
    
    print("\nå¯ç”¨æ£€æŸ¥ç‚¹åˆ—è¡¨:")
    print(f"{'ID':<5} {'ç‰ˆæœ¬':<15} {'æ—¶é—´':<20} {'ä¿¡æ¯'}")
    print("-" * 80)
    
    count = 0
    for v in versions:
        ckpt_dir = v / "checkpoints"
        if not ckpt_dir.exists():
            continue
        
        ckpts = list(ckpt_dir.glob("*.ckpt"))
        if not ckpts:
            continue
        
        # è·å–ä¿®æ”¹æ—¶é—´
        mtime = v.stat().st_mtime
        time_str = datetime.datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M')
        
        # è·å–ä¿¡æ¯
        info = get_checkpoint_info(v)
        
        count += 1
        valid_versions.append((v, ckpts[0]))
        print(f"[{count}]  {v.name:<15} {time_str:<20} {info}")
    
    if count == 0:
        print_error("æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æ£€æŸ¥ç‚¹")
        return None
    
    print("-" * 80)
    choice = input(f"è¯·é€‰æ‹©æ£€æŸ¥ç‚¹ [1-{count}] (ç›´æ¥å›è½¦é€‰æ‹©æœ€æ–°çš„): ").strip() or "1"
    
    try:
        idx = int(choice) - 1
        if 0 <= idx < len(valid_versions):
            return str(valid_versions[idx][1])
    except ValueError:
        pass
    
    print_error("æ— æ•ˆé€‰æ‹©")
    return None


# ============================================================================
# å®éªŒè¿è¡Œå‡½æ•°
# ============================================================================

def run_single_experiment(config: ExperimentConfig, 
                          run_analysis: bool = True,
                          run_visualization: bool = True) -> bool:
    """
    è¿è¡Œå•æ¬¡å®éªŒï¼ˆè®­ç»ƒ + åˆ†æ + å¯è§†åŒ–ï¼‰
    
    Args:
        config: å®éªŒé…ç½®
        run_analysis: æ˜¯å¦è¿è¡Œåˆ†æ
        run_visualization: æ˜¯å¦è¿è¡Œå¯è§†åŒ–
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    exp_name = config.get_experiment_name()
    output_dir = config.get_output_dir()
    
    print()
    print("=" * 60)
    print(f"  å®éªŒ: {exp_name}")
    print("=" * 60)
    
    total_steps = 1 + (1 if run_analysis else 0) + (2 if run_visualization else 0)
    current_step = 0
    
    # æ­¥éª¤ 1: è®­ç»ƒ
    current_step += 1
    print(f"\n[{current_step}/{total_steps}] è®­ç»ƒæ¨¡å‹...")
    
    train_cmd = [
        "python", "src/train.py",
        f"model={config.model}",
        f"dataset={config.dataset}",
        f"sr/mechanism={config.mechanism}",
        f"sr/noise={config.noise_type}",
        f"trainer.max_epochs={config.epochs}"
    ]
    
    # æ·»åŠ  GPU é…ç½®
    if config.use_cpu:
        train_cmd.append("trainer.accelerator=cpu")
    elif platform.system() != 'Windows':
        train_cmd.append(f"trainer.devices=[{config.gpu_id}]")
    
    success, _ = run_command(train_cmd)
    if not success:
        print_error("è®­ç»ƒå¤±è´¥ï¼è·³è¿‡åç»­æ­¥éª¤ã€‚")
        return False
    
    # æŸ¥æ‰¾æœ€æ–°æ£€æŸ¥ç‚¹
    ckpt_path = find_latest_checkpoint()
    if not ckpt_path:
        print_error("æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶ï¼è·³è¿‡åˆ†æå’Œå¯è§†åŒ–ã€‚")
        return False
    
    print_info(f"æ‰¾åˆ°æ£€æŸ¥ç‚¹: {ckpt_path}")
    
    # æ­¥éª¤ 2: ç”Ÿæˆè®­ç»ƒæ”¶æ•›æ›²çº¿
    if run_visualization:
        current_step += 1
        print(f"\n[{current_step}/{total_steps}] ç”Ÿæˆè®­ç»ƒæ”¶æ•›æ›²çº¿...")
        
        version_dir = find_latest_version_dir()
        if version_dir:
            curves_output_dir = f"{output_dir}/figures"
            training_curves_cmd = [
                "python", "src/visualize.py",
                "--training-curves",
                "--output-dir", curves_output_dir,
                "--prefix", f"{exp_name}_"
            ]
            run_command(training_curves_cmd)
        else:
            print_warning("æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—ç›®å½•ï¼Œè·³è¿‡è®­ç»ƒæ›²çº¿ç”Ÿæˆã€‚")
    
    # æ­¥éª¤ 3: åˆ†æ
    if run_analysis:
        current_step += 1
        print(f"\n[{current_step}/{total_steps}] è¿è¡Œåˆ†æ...")
        
        # ç¡®ä¿è·¯å¾„ä½¿ç”¨æ­£æ–œæ 
        ckpt_path_safe = ckpt_path.replace("\\", "/")
        output_dir_safe = output_dir.replace("\\", "/")
        
        analyze_cmd = [
            "python", "src/analyze.py",
            f"model={config.model}",
            f"dataset={config.dataset}",
            f"sr/mechanism={config.mechanism}",
            f"sr/noise={config.noise_type}",
            f"+ckpt_path='{ckpt_path_safe}'",
            f"+analysis.output_dir='{output_dir_safe}'"
        ]
        run_command(analyze_cmd)
    
    # æ­¥éª¤ 4: å¯è§†åŒ–
    if run_visualization:
        current_step += 1
        print(f"\n[{current_step}/{total_steps}] ç”Ÿæˆå¯è§†åŒ–...")
        
        visualize_cmd = [
            "python", "src/visualize.py",
            "--results-dir", output_dir,
            "--output-dir", f"{output_dir}/figures",
            "--dataset", config.dataset
        ]
        run_command(visualize_cmd)
    
    print_success(f"å®éªŒ {exp_name} å®Œæˆï¼")
    print_info(f"ç»“æœä¿å­˜åœ¨: {output_dir}")
    return True


def run_loso_experiment(config: ExperimentConfig,
                        fold_id: Optional[int] = None,
                        run_all_folds: bool = False,
                        n_folds: int = 9) -> bool:
    """
    è¿è¡Œ LOSO äº¤å‰éªŒè¯å®éªŒ
    è®­ç»ƒå®Œæˆåè‡ªåŠ¨è¿è¡Œåˆ†æå’Œå¯è§†åŒ–
    
    Args:
        config: å®éªŒé…ç½®
        fold_id: æŒ‡å®šçš„ fold IDï¼ˆ1-n_foldsï¼‰
        run_all_folds: æ˜¯å¦è¿è¡Œæ‰€æœ‰ folds
        n_folds: æŠ˜æ•°ï¼ˆé»˜è®¤ 9ï¼ŒçœŸæ­£çš„ LOSOï¼‰
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    exp_name = config.get_experiment_name()
    output_dir = f"./results/loso/{exp_name}"
    
    success = False
    checkpoint_paths = []
    
    if run_all_folds:
        # è¿è¡Œæ‰€æœ‰ folds
        print()
        print("=" * 60)
        print(f"  LOSO å®éªŒ: {exp_name}")
        print(f"  è¿è¡Œæ‰€æœ‰ {n_folds} ä¸ª Folds")
        print("=" * 60)
        
        progress = ProgressBar(n_folds, width=30)
        success_count = 0
        
        for fold in range(1, n_folds + 1):
            print(f"\n{'='*60}")
            print(f"  æ­£åœ¨è¿è¡Œ Fold {fold}/{n_folds}")
            print(f"{'='*60}")
            
            fold_success, ckpt_path = _run_single_loso_fold(config, fold, output_dir, n_folds)
            if fold_success:
                success_count += 1
                if ckpt_path:
                    checkpoint_paths.append(ckpt_path)
            
            progress.update(fold, f"Fold {fold} å®Œæˆ")
        
        print_success(f"LOSO å®éªŒå®Œæˆï¼æˆåŠŸ {success_count}/{n_folds} ä¸ª Folds")
        success = success_count > 0
    
    elif fold_id:
        # è¿è¡Œå•ä¸ª fold
        print()
        print("=" * 60)
        print(f"  LOSO å®éªŒ: {exp_name}")
        print(f"  Fold: {fold_id}/{n_folds}")
        print("=" * 60)
        
        fold_success, ckpt_path = _run_single_loso_fold(config, fold_id, output_dir, n_folds)
        success = fold_success
        if ckpt_path:
            checkpoint_paths.append(ckpt_path)
    
    else:
        print_error("è¯·æŒ‡å®š fold_id æˆ–è®¾ç½® run_all_folds=True")
        return False
    
    # è®­ç»ƒå®Œæˆåè‡ªåŠ¨è¿è¡Œåˆ†æå’Œå¯è§†åŒ–
    if success and checkpoint_paths:
        print()
        print_separator("â•")
        print_info("è®­ç»ƒå®Œæˆï¼Œè‡ªåŠ¨å¼€å§‹åå¤„ç†...")
        print_separator("â•")
        
        # ä½¿ç”¨æœ€åä¸€ä¸ª checkpoint è¿›è¡Œåˆ†æ
        ckpt_path = checkpoint_paths[-1]
        
        # æ­¥éª¤ 1: è¿è¡Œå™ªå£°æ‰«æåˆ†æ
        print()
        print_info("[1/3] è¿è¡Œå™ªå£°æ‰«æåˆ†æ...")
        run_analysis_only(ckpt_path, config, output_dir)
        
        # æ­¥éª¤ 2: ç”Ÿæˆè®­ç»ƒæ”¶æ•›æ›²çº¿
        print()
        print_info("[2/3] ç”Ÿæˆè®­ç»ƒæ”¶æ•›æ›²çº¿...")
        version_dir = find_latest_version_dir()
        if version_dir:
            curves_output_dir = f"{output_dir}/figures"
            training_curves_cmd = [
                "python", "src/visualize.py",
                "--training-curves",
                "--output-dir", curves_output_dir,
                "--prefix", f"{exp_name}_"
            ]
            run_command(training_curves_cmd)
        else:
            print_warning("æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—ç›®å½•ï¼Œè·³è¿‡è®­ç»ƒæ›²çº¿ç”Ÿæˆã€‚")
        
        # æ­¥éª¤ 3: ç”Ÿæˆåˆ†æç»“æœå¯è§†åŒ–
        print()
        print_info("[3/3] ç”Ÿæˆåˆ†æç»“æœå¯è§†åŒ–...")
        run_visualization_only(
            results_dir=output_dir,
            include_training_curves=False,
            dataset=config.dataset
        )
        
        print()
        print_separator("â•")
        print_success(f"æ‰€æœ‰å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")
        print_separator("â•")
    elif success:
        print_warning("æœªæ‰¾åˆ° checkpointï¼Œè·³è¿‡è‡ªåŠ¨åˆ†æå’Œå¯è§†åŒ–")
    
    return success


def _run_single_loso_fold(config: ExperimentConfig,
                          fold_id: int,
                          output_dir: str,
                          n_folds: int = 9) -> Tuple[bool, Optional[str]]:
    """
    è¿è¡Œå•ä¸ª LOSO fold
    
    Args:
        config: å®éªŒé…ç½®
        fold_id: fold ID
        output_dir: è¾“å‡ºç›®å½•
        n_folds: æŠ˜æ•°
    
    Returns:
        (æ˜¯å¦æˆåŠŸ, checkpointè·¯å¾„)
    """
    # æ„å»º LOSO è®­ç»ƒå‘½ä»¤
    train_cmd = [
        "python", "src/loso_train.py",
        f"model={config.model}",
        f"dataset={config.dataset}",
        f"sr/mechanism={config.mechanism}",
        f"sr/noise={config.noise_type}",
        f"trainer.max_epochs={config.epochs}",
        f"dataset.n_folds={n_folds}",
        f"dataset.fold_id={fold_id}"
    ]
    
    # æ·»åŠ  GPU é…ç½®
    if config.use_cpu:
        train_cmd.append("trainer.accelerator=cpu")
    elif platform.system() != 'Windows':
        train_cmd.append(f"trainer.devices=[{config.gpu_id}]")
    
    success, _ = run_command(train_cmd, "å¼€å§‹ LOSO è®­ç»ƒ...")
    
    if not success:
        print_error(f"Fold {fold_id} è®­ç»ƒå¤±è´¥ï¼")
        return False, None
    
    # æŸ¥æ‰¾æœ€æ–°çš„ checkpoint
    ckpt_path = find_latest_checkpoint()
    
    print_success(f"Fold {fold_id} å®Œæˆï¼")
    return True, ckpt_path


def run_batch_experiments(configs: List[ExperimentConfig],
                          run_analysis: bool = True,
                          run_visualization: bool = True) -> Tuple[int, int]:
    """
    è¿è¡Œæ‰¹é‡å®éªŒ
    
    Args:
        configs: é…ç½®åˆ—è¡¨
        run_analysis: æ˜¯å¦è¿è¡Œåˆ†æ
        run_visualization: æ˜¯å¦è¿è¡Œå¯è§†åŒ–
        
    Returns:
        (æˆåŠŸæ•°, æ€»æ•°)
    """
    total = len(configs)
    success_count = 0
    
    print()
    print("=" * 60)
    print(f"  æ‰¹é‡å®éªŒ: å…± {total} ä¸ªé…ç½®")
    print("=" * 60)
    
    for i, config in enumerate(configs, 1):
        exp_name = config.get_experiment_name()
        print(f"\n[{i}/{total}] è¿è¡Œ: {exp_name}")
        
        if run_single_experiment(config, run_analysis, run_visualization):
            success_count += 1
    
    print()
    print("=" * 60)
    print_success(f"æ‰¹é‡å®éªŒå®Œæˆï¼æˆåŠŸ {success_count}/{total}")
    print("=" * 60)
    
    return success_count, total


def run_analysis_only(ckpt_path: str, 
                      config: Optional[ExperimentConfig] = None,
                      output_dir: str = "./results/analysis") -> bool:
    """
    ä»…è¿è¡Œåˆ†æ
    
    Args:
        ckpt_path: æ£€æŸ¥ç‚¹è·¯å¾„
        config: å®éªŒé…ç½®ï¼ˆå¯é€‰ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    print_menu_header("æ¨¡å‹åˆ†æ", "ğŸ“Š")
    
    print_info(f"æ£€æŸ¥ç‚¹: {ckpt_path}")
    print_info(f"è¾“å‡ºç›®å½•: {output_dir}")
    print()
    
    # ç¡®ä¿è·¯å¾„ä½¿ç”¨æ­£æ–œæ 
    ckpt_path_safe = ckpt_path.replace("\\", "/")
    output_dir_safe = output_dir.replace("\\", "/")
    
    cmd = [
        "python", "src/analyze.py",
        f"+ckpt_path='{ckpt_path_safe}'",
        f"+analysis.output_dir='{output_dir_safe}'"
    ]
    
    # å¦‚æœæä¾›äº†é…ç½®ï¼Œæ·»åŠ æ¨¡å‹å’Œæ•°æ®é›†ä¿¡æ¯
    if config:
        cmd.insert(2, f"model={config.model}")
        cmd.insert(3, f"dataset={config.dataset}")
        cmd.insert(4, f"sr/mechanism={config.mechanism}")
        cmd.insert(5, f"sr/noise={config.noise_type}")
    
    success, _ = run_command(cmd)
    
    if success:
        print_success("åˆ†æå®Œæˆï¼")
    else:
        print_error("åˆ†æå¤±è´¥ï¼")
    
    return success


def run_visualization_only(results_dir: str = "./results/analysis",
                           output_dir: str = None,
                           include_training_curves: bool = True,
                           dataset: str = "bci2a") -> bool:
    """
    ä»…è¿è¡Œå¯è§†åŒ–
    
    Args:
        results_dir: ç»“æœç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        include_training_curves: æ˜¯å¦åŒ…å«è®­ç»ƒæ›²çº¿
        dataset: æ•°æ®é›†åç§°
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    if output_dir is None:
        output_dir = f"{results_dir}/figures"
    
    success = True
    
    # ç”Ÿæˆåˆ†æç»“æœå¯è§†åŒ–
    print_info("ç”Ÿæˆåˆ†æç»“æœå¯è§†åŒ–...")
    cmd = [
        "python", "src/visualize.py",
        "--results-dir", results_dir,
        "--output-dir", output_dir,
        "--dataset", dataset
    ]
    s, _ = run_command(cmd)
    success = success and s
    
    # ç”Ÿæˆè®­ç»ƒæ›²çº¿
    if include_training_curves:
        print_info("ç”Ÿæˆè®­ç»ƒæ”¶æ•›æ›²çº¿...")
        cmd = [
            "python", "src/visualize.py",
            "--training-curves",
            "--output-dir", output_dir
        ]
        s, _ = run_command(cmd)
        success = success and s
    
    if success:
        print_success(f"å¯è§†åŒ–å®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")
    else:
        print_warning("éƒ¨åˆ†å¯è§†åŒ–ä»»åŠ¡å¤±è´¥")
    
    return success


# ============================================================================
# æ™ºèƒ½å¤š GPU å¹¶è¡Œæ‰¹é‡ LOSO å®éªŒ
# ============================================================================

def run_batch_loso_parallel(
    configs: List[ExperimentConfig],
    n_folds: int = 9,
    gpu_ids: List[int] = None
) -> Tuple[int, int]:
    """
    æ™ºèƒ½å¹¶è¡Œæ‰¹é‡ LOSO å®éªŒ
    
    è‡ªåŠ¨é€‚é…ç¡¬ä»¶ç¯å¢ƒ:
    - æ—  GPU: å•è¿›ç¨‹ CPU é¡ºåºæ‰§è¡Œ
    - å• GPU: å•è¿›ç¨‹ GPU é¡ºåºæ‰§è¡Œï¼ˆæ— è¿›ç¨‹å¼€é”€ï¼‰
    - å¤š GPU: multiprocessing é˜Ÿåˆ— + å¤š worker å¹¶è¡Œ
    
    Args:
        configs: å®éªŒé…ç½®åˆ—è¡¨
        n_folds: æ¯ä¸ªé…ç½®çš„ LOSO æŠ˜æ•°
        gpu_ids: è¦ä½¿ç”¨çš„ GPU ID åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
        
    Returns:
        (æˆåŠŸæ•°, æ€»ä»»åŠ¡æ•°)
    """
    import torch
    
    # è‡ªåŠ¨æ£€æµ‹å¯ç”¨ GPU
    if gpu_ids is None:
        gpu_count = torch.cuda.device_count()
        if gpu_count == 0:
            print_info("æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU æ¨¡å¼")
            return _run_batch_loso_cpu(configs, n_folds)
        else:
            gpu_ids = list(range(gpu_count))
    
    if len(gpu_ids) == 0:
        print_info("æœªæŒ‡å®š GPUï¼Œä½¿ç”¨ CPU æ¨¡å¼")
        return _run_batch_loso_cpu(configs, n_folds)
    elif len(gpu_ids) == 1:
        # å• GPU ä¼˜åŒ–ï¼šé¿å… multiprocessing å¼€é”€
        print_info(f"ä½¿ç”¨å• GPU æ¨¡å¼ (GPU {gpu_ids[0]})")
        return _run_batch_loso_single_gpu(configs, n_folds, gpu_ids[0])
    else:
        # å¤š GPUï¼šå¯åŠ¨ worker è¿›ç¨‹
        print_info(f"ä½¿ç”¨å¤š GPU å¹¶è¡Œæ¨¡å¼ (GPU: {gpu_ids})")
        return _run_batch_loso_multi_gpu(configs, n_folds, gpu_ids)


def _run_batch_loso_cpu(
    configs: List[ExperimentConfig],
    n_folds: int
) -> Tuple[int, int]:
    """CPU æ¨¡å¼é¡ºåºæ‰§è¡Œæ‰¹é‡ LOSO"""
    total = len(configs) * n_folds
    success = 0
    
    print()
    print("=" * 60)
    print(f"  æ‰¹é‡ LOSO (CPU æ¨¡å¼)")
    print(f"  é…ç½®æ•°: {len(configs)}, æ¯é…ç½®æŠ˜æ•°: {n_folds}")
    print(f"  æ€»ä»»åŠ¡æ•°: {total}")
    print("=" * 60)
    
    progress = ProgressBar(total, width=40)
    task_idx = 0
    
    for config in configs:
        config.use_cpu = True
        exp_name = config.get_experiment_name()
        output_dir = f"./results/loso/{exp_name}"
        
        for fold_id in range(1, n_folds + 1):
            task_idx += 1
            print(f"\n[{task_idx}/{total}] {exp_name} - Fold {fold_id}")
            
            fold_success, _ = _run_single_loso_fold(config, fold_id, output_dir, n_folds)
            if fold_success:
                success += 1
            
            progress.update(task_idx, f"Fold {fold_id} å®Œæˆ")
    
    print()
    print_separator("â•")
    print_success(f"æ‰¹é‡ LOSO å®Œæˆï¼æˆåŠŸ {success}/{total}")
    print_separator("â•")
    
    return success, total


def _run_batch_loso_single_gpu(
    configs: List[ExperimentConfig],
    n_folds: int,
    gpu_id: int
) -> Tuple[int, int]:
    """å• GPU é¡ºåºæ‰§è¡Œæ‰¹é‡ LOSOï¼ˆæ— è¿›ç¨‹å¼€é”€ï¼‰"""
    # è®¾ç½® GPU
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
    
    total = len(configs) * n_folds
    success = 0
    
    print()
    print("=" * 60)
    print(f"  æ‰¹é‡ LOSO (å• GPU æ¨¡å¼, GPU {gpu_id})")
    print(f"  é…ç½®æ•°: {len(configs)}, æ¯é…ç½®æŠ˜æ•°: {n_folds}")
    print(f"  æ€»ä»»åŠ¡æ•°: {total}")
    print("=" * 60)
    
    progress = ProgressBar(total, width=40)
    task_idx = 0
    
    for config in configs:
        config.use_cpu = False
        config.gpu_id = 0  # CUDA_VISIBLE_DEVICES å·²è®¾ç½®ï¼Œä½¿ç”¨è®¾å¤‡ 0
        exp_name = config.get_experiment_name()
        output_dir = f"./results/loso/{exp_name}"
        
        for fold_id in range(1, n_folds + 1):
            task_idx += 1
            print(f"\n[{task_idx}/{total}] {exp_name} - Fold {fold_id}")
            
            fold_success, _ = _run_single_loso_fold(config, fold_id, output_dir, n_folds)
            if fold_success:
                success += 1
            
            progress.update(task_idx, f"Fold {fold_id} å®Œæˆ")
    
    print()
    print_separator("â•")
    print_success(f"æ‰¹é‡ LOSO å®Œæˆï¼æˆåŠŸ {success}/{total}")
    print_separator("â•")
    
    return success, total


def _run_batch_loso_multi_gpu(
    configs: List[ExperimentConfig],
    n_folds: int,
    gpu_ids: List[int]
) -> Tuple[int, int]:
    """å¤š GPU å¹¶è¡Œæ‰§è¡Œæ‰¹é‡ LOSO"""
    
    # æ„å»ºä»»åŠ¡é˜Ÿåˆ—
    task_queue = mp.Queue()
    result_queue = mp.Queue()
    
    total_tasks = 0
    for config in configs:
        exp_name = config.get_experiment_name()
        output_dir = f"./results/loso/{exp_name}"
        for fold_id in range(1, n_folds + 1):
            # åºåˆ—åŒ–é…ç½®ä¸ºå­—å…¸
            task = {
                "model": config.model,
                "dataset": config.loso_dataset,
                "mechanism": config.mechanism,
                "noise_type": config.noise_type,
                "epochs": config.epochs,
                "batch_size": config.batch_size,
                "fold_id": fold_id,
                "n_folds": n_folds,
                "output_dir": output_dir,
                "exp_name": exp_name
            }
            task_queue.put(task)
            total_tasks += 1
    
    # æ·»åŠ ç»ˆæ­¢ä¿¡å·ï¼ˆæ¯ä¸ª worker ä¸€ä¸ªï¼‰
    for _ in gpu_ids:
        task_queue.put(None)
    
    print()
    print("=" * 60)
    print(f"  æ‰¹é‡ LOSO (å¤š GPU å¹¶è¡Œæ¨¡å¼)")
    print(f"  GPU: {gpu_ids}")
    print(f"  é…ç½®æ•°: {len(configs)}, æ¯é…ç½®æŠ˜æ•°: {n_folds}")
    print(f"  æ€»ä»»åŠ¡æ•°: {total_tasks}")
    print("=" * 60)
    print()
    print_info("å¯åŠ¨ GPU workers...")
    
    # æ¯ä¸ª GPU å¯åŠ¨ä¸€ä¸ª worker
    workers = []
    for gpu_id in gpu_ids:
        p = mp.Process(
            target=_gpu_worker,
            args=(task_queue, result_queue, gpu_id)
        )
        p.start()
        workers.append(p)
        print_info(f"  Worker å¯åŠ¨: GPU {gpu_id} (PID: {p.pid})")
    
    # ç­‰å¾…æ‰€æœ‰ worker å®Œæˆ
    print()
    print_info("ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
    for p in workers:
        p.join()
    
    # ç»Ÿè®¡ç»“æœ
    success_count = 0
    while not result_queue.empty():
        result = result_queue.get()
        if result.get("success", False):
            success_count += 1
    
    print()
    print_separator("â•")
    print_success(f"æ‰¹é‡ LOSO å®Œæˆï¼æˆåŠŸ {success_count}/{total_tasks}")
    print_separator("â•")
    
    return success_count, total_tasks


def _gpu_worker(task_queue: mp.Queue, result_queue: mp.Queue, gpu_id: int):
    """
    å• GPU worker: ä¸æ–­ä»é˜Ÿåˆ—å–ä»»åŠ¡æ‰§è¡Œ
    
    Args:
        task_queue: ä»»åŠ¡é˜Ÿåˆ—
        result_queue: ç»“æœé˜Ÿåˆ—
        gpu_id: åˆ†é…çš„ GPU ID
    """
    # è®¾ç½® CUDA_VISIBLE_DEVICES
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
    
    while True:
        try:
            task = task_queue.get(timeout=1)
        except Empty:
            continue
        
        if task is None:
            # æ”¶åˆ°ç»ˆæ­¢ä¿¡å·
            break
        
        # æ‰§è¡Œä»»åŠ¡
        success = _run_single_loso_task(task)
        result_queue.put({
            "success": success,
            "exp_name": task.get("exp_name", ""),
            "fold_id": task.get("fold_id", 0),
            "gpu_id": gpu_id
        })


def _run_single_loso_task(task: dict) -> bool:
    """
    æ‰§è¡Œå•ä¸ª LOSO ä»»åŠ¡
    
    Args:
        task: ä»»åŠ¡å­—å…¸ï¼ŒåŒ…å«é…ç½®ä¿¡æ¯
        
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    # æ„å»ºè®­ç»ƒå‘½ä»¤
    cmd = [
        "python", "src/loso_train.py",
        f"model={task['model']}",
        f"dataset={task['dataset']}",
        f"sr/mechanism={task['mechanism']}",
        f"sr/noise={task['noise_type']}",
        f"trainer.max_epochs={task['epochs']}",
        f"dataset.n_folds={task['n_folds']}",
        f"dataset.fold_id={task['fold_id']}"
    ]
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        return result.returncode == 0
    except Exception as e:
        print(f"ä»»åŠ¡æ‰§è¡Œé”™è¯¯: {e}")
        return False


# ============================================================================
# ä¸€é”®åˆ†æä¸å¯è§†åŒ–æµç¨‹
# ============================================================================

def run_full_analysis_pipeline(
    ckpt_path: str,
    config: ExperimentConfig,
    output_dir: str
) -> bool:
    """
    ä¸€é”®è¿è¡Œå®Œæ•´çš„åˆ†æå’Œå¯è§†åŒ–æµç¨‹
    
    æµç¨‹:
    1. å™ªå£°æ‰«æåˆ†æ (analyze.py)
    2. è®­ç»ƒæ”¶æ•›æ›²çº¿ (visualize.py --training-curves)
    3. åˆ†æç»“æœå¯è§†åŒ– (visualize.py --results-dir)
    
    Args:
        ckpt_path: æ£€æŸ¥ç‚¹è·¯å¾„
        config: å®éªŒé…ç½®
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        æ˜¯å¦å…¨éƒ¨æˆåŠŸ
    """
    print_menu_header("ä¸€é”®åˆ†æä¸å¯è§†åŒ–", "ğŸ¯")
    
    exp_name = config.get_experiment_name()
    success = True
    
    print_info(f"å®éªŒ: {exp_name}")
    print_info(f"Checkpoint: {ckpt_path}")
    print_info(f"è¾“å‡ºç›®å½•: {output_dir}")
    print()
    
    # æ­¥éª¤ 1: å™ªå£°æ‰«æåˆ†æ
    print()
    print_separator("â”€")
    print_info("[1/3] è¿è¡Œå™ªå£°æ‰«æåˆ†æ...")
    print_separator("â”€")
    
    if not run_analysis_only(ckpt_path, config, output_dir):
        print_warning("å™ªå£°æ‰«æåˆ†æå¤±è´¥ï¼Œç»§ç»­åç»­æ­¥éª¤...")
        success = False
    
    # æ­¥éª¤ 2: è®­ç»ƒæ”¶æ•›æ›²çº¿
    print()
    print_separator("â”€")
    print_info("[2/3] ç”Ÿæˆè®­ç»ƒæ”¶æ•›æ›²çº¿...")
    print_separator("â”€")
    
    version_dir = find_latest_version_dir()
    if version_dir:
        curves_output_dir = f"{output_dir}/figures"
        os.makedirs(curves_output_dir, exist_ok=True)
        
        training_curves_cmd = [
            "python", "src/visualize.py",
            "--training-curves",
            "--output-dir", curves_output_dir,
            "--prefix", f"{exp_name}_"
        ]
        s, _ = run_command(training_curves_cmd, show_output=True)
        if not s:
            print_warning("è®­ç»ƒæ›²çº¿ç”Ÿæˆå¤±è´¥")
            success = False
    else:
        print_warning("æœªæ‰¾åˆ°è®­ç»ƒæ—¥å¿—ç›®å½•ï¼Œè·³è¿‡è®­ç»ƒæ›²çº¿ç”Ÿæˆ")
    
    # æ­¥éª¤ 3: åˆ†æç»“æœå¯è§†åŒ–
    print()
    print_separator("â”€")
    print_info("[3/3] ç”Ÿæˆåˆ†æç»“æœå¯è§†åŒ–...")
    print_separator("â”€")
    
    # ç¡®å®šæ•°æ®é›†åç§°ï¼ˆå»æ‰ _loso åç¼€ç”¨äºç±»åˆ«åç§°ï¼‰
    dataset_for_viz = config.dataset.replace("_loso", "") if "_loso" in config.dataset else config.dataset
    
    viz_cmd = [
        "python", "src/visualize.py",
        "--results-dir", output_dir,
        "--output-dir", f"{output_dir}/figures",
        "--dataset", dataset_for_viz
    ]
    s, _ = run_command(viz_cmd, show_output=True)
    if not s:
        print_warning("åˆ†æç»“æœå¯è§†åŒ–å¤±è´¥")
        success = False
    
    # æ€»ç»“
    print()
    print_separator("â•")
    if success:
        print_success(f"æ‰€æœ‰å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {output_dir}")
    else:
        print_warning(f"éƒ¨åˆ†å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚ç»“æœåœ¨: {output_dir}")
    print_separator("â•")
    
    return success